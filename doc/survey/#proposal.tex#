\documentclass[10pt]{article}         %% What type of document you're writing.

\usepackage{amsmath,amsfonts,amssymb,mathtools}   %% AMS mathematics macros
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

\title{Research proposal: Statistical Visual Odometry}
\author{Ehud Rivlin, Ilan Shimshoni, Alex Kreimer}
\bibliographystyle{ieeetr}
\begin{document}

\maketitle

\begin{abstract} 
Visual odometry is the process of estimating the ego-motion of the agent (e.g, human, vehicle) using only the input of a single or multiple cameras attached to it.  In this work we propose a novel stereo visual odometry algorithm which uses motion priors, uncertainty modeling/propagation and maximum likelihood based inference procedure, that incorporates uncertainty measurements, to improve current resutls.  In order to test our algorithm, we build a hardware setup that is capable to produce video sequences and ground truth suitable for stereo visual odometry algorithms.
\end{abstract}
\section{Introduction}

Visual Odometry has been successfully used in scientific and industrial environments (see \cite{Maimone07twoyears} for an example on VO on Mars exploration rovers). Keeping track of a vehicle's location is one of the most challenging aspects of building an autonomous vehicle.  The advantage of VO with respect to wheel odometry is that VO is not affected by wheel slip in uneven terrain or other adverse conditions.  It has been demonstrated that compared to wheel odometry, VO provides more accurate trajectory estimates, and thus it matured from a ``nice to have'' capability into a critical autonomous vehicle system.

VO odometry system comprises a software for processing stereo pairs taken by the cameras.  The system computes and updates the 6 Degree of Freedom vehicle pose (x, y, z, roll, pitch, yaw) by tracking the motion of image features.

In section ~\ref{sect:related} we do a brief summary of a related work in the field, in section ~\ref{sect:main_idea} we state the main idea of our work, sections ~\ref{sect:algorithm} and ~\ref{sect:setup} go into the details of the proposed algorithm and the setup that we use.

\section{Related work}\label{sect:related}
Work on estimating motion with stereo cameras can be traced back to Moravec's work \cite{Moravec:1980:OAN:909315}. Following Moravec's work, Matthies et al. treated motion estimation as a statistical estimation problem and developed sequential methods for estimating the vehicle motion and updating the landmark models. This system achieved an accuracy of 2\% of distance over 5.5 meters and 55 stereo image pairs (\cite{Matthies87errormodeling};\cite{Matthies:1989:DSV:916891}) with a consistent level of accuracy reported more recently (\cite{olson2003rover}). Similar work has been reported elsewhere (\cite{zhang1988analysis}, \cite{lacroix1999rover}, \cite{nister2004visual}). Recently, Nister et al. have reported a successful real-time Visual Odometry implementation (\cite{nister2006visual},\cite{nister2004efficient}). This implementation contains two motion estimation schemes: the stereo scheme, which is an iterative pose refinement scheme, and the monocular scheme, which was based on the framework of the 5-point algorithm \cite{nister2004efficient} and the outlier rejection scheme \cite{nister2005preemptive} and good results have been reported on very long image sequences. Other approaches to the subject of Visual Odometry schemes have been reported as well.  For example, McCarthy and Barnes have reported the performance of optical flow based motion estimation (\cite{mccarthy2004performance}) and Vassalo and Gluckman and others have developed ego-motion estimation with omnidirectional images \cite{vassallo2002general},\cite{gluckman1998ego},\cite{corke2004omnidirectional}.

\section{Main idea}\label{sect:main_idea}
In this work we seek to build an end to end VO system which comprises the following parts:
\begin{enumerate}
\item Implement a novel VO algorithm which exploits vehicle motion priors and uncertainty modeling/propagation to improve current results.
\item Hardware setup that is capable to capture the video sequences and to produce ground truth to evaluate a VO algorithm.  The setup will be used to evalue the performance of the algorithm along with an industry standard datasets (e.g. \cite{Geiger2012CVPR})
\end{enumerate}

Below we summarize novel features of our algorithm:
\begin{enumerate}
\item Motion priors (e.g., \cite{scaramuzza2011exploiting}) we used in a mono VO algorithm, while we propose to use them in stereo VO
\item We propose to model uncertainty of the image features with the application to stereo VO algorithm, which was not done before
\item We propose to incorporate image features/3D points uncertainty into 3D-to-2D reprojection error minimization scheme, which was not done before (it was done in 3D-to-3D setting)
\end{enumerate}
In the following sections we describe in more detail each part of our proposal.

\section{Novel visual odometry algorithm}\label{sect:algorithm}
\subsection{Motion priors}
Motion priors for VO mean that we would like to exploit our knowledge of the problem (e.g., the vehicle can not jump) to improve existing results.

One of the main issues in VO algorithm is a presence of outliers in feature matching.  Usually, a RANSAC procedure is employed to cope with the problem.  Its drawback is that the number of required RANSAC iterations grows exponentially and thus a wrong hypothesis may be chosen.  One of the ways to improve the situation is to build a ``proposal distribution'' (e.g., \cite{scaramuzza2011exploiting}) and use it to sample the data, instead of random RANSAC sampling.  They show that this approach improves the runtime of the algorithm and yields more accurate results, which favor solutions that comply with vehicle motion constraints.

\subsection{Statistical VO}

We use \cite{Geiger2012CVPR} as the baseline algorithm. Our goal in this part of the research is to use uncertainty modeling and error propagation to improve the existing VO results. Previous studies suggest that the value of uncertainty modeling in vision algorithms may vary greatly depending on how close the model is to the true noise distribution (see  \cite{brooks2001value}, \cite{kanazawa2001we} for a discussion).

With regards to uncertainty modeling/propagation our algorithm may be divided into three parts:
\begin{enumerate}
\item Feature processing. We plan to use Harris corners as features, since they posses the required properties: fast, robust and provide a large number of features. These features are discussed in section ~\ref{subsect:harris_stats}
\item Triangulation procedure. We plan to evaluate empirically a number of algorithms. (Naive, DLT, Gold standard, see \cite{Hartley2004}). This will be discussed in ~\ref{subsect:3D_stats}
\item Motion parameters ($\textbf{r,t}$) fitting procedure, which will be discussed in ~\ref{subsect:param_fit}
\end{enumerate}

\subsection{Statistical characteristics of Harris corners}\label{subsect:harris_stats}
The incentive of modeling uncertainty (represented by a covariance matrix) for feature points is rather simple: not all corners are the same w.r.t. their tracking properties.  We plan to evaluate a number different methods proposed in the literature to model the uncertainty of Harris corners (e.g., \cite{orguner2007statistical}, \cite{brooks2001value}) and their influence on the VO.  It is worth to say that previous studies explored uncertainty propagation mainly in (bi)-linear estimation problems, which is not the case for VO.

The results of this step is a pair of covariance matrices $\Sigma_L/\Sigma_R$ for the features in the left and right images respectively.

\subsection{Statistical characteristics of reconstructed 3D points}\label{subsect:3D_stats}

The next important step w.r.t. error propagation is a triangulation of image features into the corresponding 3D points.  Given the covariance matrices $\Sigma_L,\Sigma_R$ the covariance matrix of the 3D point is given by: (this is commonly reffered to as ``sandwitch covariance''): $ \Sigma_{X} = J\begin{pmatrix}\Sigma_L&0\\  0& \Sigma_R\\  \end{pmatrix} J'$, where J is the Jacobian of the triangulation algorithm (it may either be calculated analytically or computed numerically, depending on the triangulation algorithm).  This method was successfully used in  \cite{matthies1989dynamic}.
The work of \cite{matthies1989dynamic} uses a similar up to this point procedure to model the uncertainty of the 3D points.

\subsection{Robust parameter fitting}\label{subsect:param_fit}
At this point our proposed algorithm and the algorithm proposed in the paper diverge.  Their work proposes to reconstruct the features of a new frame into 3D and solve 3D-to-3D rigid motion problem.  Previous research has shown (TODO: fill in the ref, still can't find this paper) that 3D-to-2D reprojection error minimization is superior to the 3D-to-3D method and thus our proposition is to use the computed uncertainty in the 3D points to minimize reprojection error in the new frame directly. The maximum likelihood based solution leads to the following minimization problem:
\[
\textbf{[r,t]} = \underset{\textbf{r,t}}{\text{argmin}} \sum_i (x_i-\hat{x}_i(\textbf{r,t}))'\Sigma_{x_i}(\textbf{r,t})(x_i-\hat{x}_i(\textbf{r,t}))
\]
where $x,\hat{x}$ are observed and predicted feature locations, $\textbf{r,t}$ are camera motion parameters, $\Sigma_{x_i}(\textbf{r,t})$ is uncertainty information derived from previous steps.  Note that if covariance matrices are modeled as identity we obtain the minimization procedure used in \cite{Geiger2011IV}.
\section{Hardware setup}\label{sect:setup}

The setup is intended to recover the motion of a vehicle in an urban or rural environment by a sole use of stereo image sequences.  It comprises a number of parts:
\begin{enumerate}
\item A calibrated and synchronized stereo rig. While it is relatively easy to build a calibrated stereo rig, installing it on a moving vehicle poses a new challenge: video stream syncronization, which is required by a stereo algorithm.  We use hardware camera sync, which guarantees the desired result.
\item (D)GPS, IMU units to produce a ground truth.  These units should provide data that is in sync with the cameras, which poses a challenge.
\end{enumerate}
As stated before, the setup will be used to evalue the performance of the algorithm along with the industry standard datasets (e.g. \cite{Geiger2012CVPR})

\bibliographystyle{plain}
\bibliography{proposal}
\end{document}

