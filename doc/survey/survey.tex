\documentclass[10pt]{article}         %% What type of document you're writing.

\usepackage{amsmath,amsfonts,amssymb,mathtools}   %% AMS mathematics macros
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

\title{Visual Odometry: Literature Survey}
\author{Alex Kreimer}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\subsection{Monocular Visual Odometry in Urban Environments Using an
  Omnidirectional Camera}
\cite{tardif2008monocular} solve monocular odometry.  The contribution
of the paper is that they decouple the rotation estimation from the
translation in order to estimate the pose of a new image.  The reason
why this works is that reconstruction of far away 3d points is very
poor and thus these points are a ``burden'' on a re-projection error
minimization methods.  The authors make use of these features by
computing epipolar geometry and recovering rotation out of it.  This
method significantly reduces drift over the state of the art methods
(the algorithm is tested on a 2.5 km sequence).  Translation
scale/direction is still recovered using 3d based method.  They use
SIFT instead of Harris since it gave better results.

\subsection{The Fundamental matrix: theory, algorithms, and stability
  analysis}
This work ~\cite{luong1996fundamental} defines the Fundamental matrix
as used today.  Before it was common to use the Essential matrix to
express the geometry of 2 views.  The advantage of using F is that the
camera does not have to be calibrated.  The authors develop the
formalism of F, propose estimation methods, analyze their stability
and study degenerate configurations.  Stability of the estimation is
measured by error in the epipole (the authors argue that usually this
is most commonly used computation result).  The results show that
linear (8-point) estimation method is highly sensitive to noise
(especially if the epipole is in the image) and may always be improved
by non-linear refinement.  They study two different methods to
parameterize F and a number of different optimization objectives (the
best being Sampson error).

\subsection{Real Time Localization and 3D Reconstruction}
The work ~\cite{mouragnon2006real} estimates a motion of a calibrated
camera (mono) set on an experimental vehicle.  Interest points (Harris) are
tracked and matched (ZNCC score). Robust estimates of the camera motion are
computed in real-time, key-frames are selected and permit the features
3D reconstruction.  The author introduce a procedure they call local
bundle adjustment that ensures both good accuracy and consistency over
long sequences. ~\cite{nister2004efficient} is used to initialize the pose.

\subsection{Refining essential matrix estimates from RANSAC}
The paper deals with the problem of estimating relative pose of two
cameras from outlier contaminated feature correspondences.  It is a
common practice to use RANSAC with conjunction with a linear method to
estimate a model (in this case the Essential matrix) and then to
refine it using non-linear optimization
method. ~\cite{botterillrefining} evaluate several refinement methods
which minimize functions of Sampson's error.  All perform well on
range sets of correspondences or sets with low outlier rates; but many
perform poorly otherwise.  The most accurate solution is give by
minimizing a robust function (Blake-Zisserman) of a Sampson's error.
The rotations are parameterized as quaternions and the optimization is
performed over the essential manifold, see ~\cite{schmidt2001using}.
The authors use IRLS combined with LM ~\cite{marquardt1963algorithm}
method to optimize the objective.

\subsection{Vision-based robot localization without explicit object models}
~\cite{dudek1996vision} propose a solution to localize a robot in an
unknown 2d environment using visual input. The authors train neural
net as a regression model N(I)=(x,y).  As an input for the net they
use image statistics (first and second moments of the edge
distributions, mean edge orientations, densities of lines).

\subsection{Visual Homing: Surfing on the Epipoles}
~\cite{basri1999visual} propose a solution for visual homing.  Using
this method a robot can be sent to desired positions and orientations
in 3D space specified by single images taken from these positions.
The method is based on estimating epipolar geometry between a pair of
views. A 3D model of the environment is not required.  Using the
epipolar geometry most of the parameters which specify the differences
in position and orientation of the camera between the two images are
recovered.  From a pair of images translation may be recovered only up
to a signed scale.  In order to find out the real distance the robot
make an extra step and takes an additional image.  The authors prove
that when the camera moves on a straight line the features move along
the epipolar lines while their coordinates and the coordinate of the
epipole obey the cross-ratio relation.

\subsection{A way to parameterize rotations}
~\cite{schmidt2001using} proposes a method to use quaternions in an
unconstrained nonlinear optimization.  Quaternions representing
rotation have four elements but only three degrees of freedom, since
they have to be of norm one.  This constraint has to be taken into
account when applying e.g. Levenberg-Marquardt algorithm.  One of the
ways to address this issue is to use appropriate parameterization
(others are a projection step and Lagrange multipliers). Well known
parameterizations are Euler angles and axis-angle representation.

~\cite{hornegger1999representation} call a parameterization fair if it
does not introduce more numerical sensitivity than inherent to the
problem itself.  This is guaranteed, if any rigid transformation of
the space to be parameterized results in an orthogonal transformation
of the parameters.  Both axis-angle and quaternion parameterizations
are fair, while Euler angles is not.

Authors search for a parameteriation that:
\begin{enumerate}
\item is minimal, i.e. uses only three parameters
\item the three parameters may be changed arbitrarily by the optimization algorithm
\item the resulting quaternion has always norm 1.
\end{enumerate}

This new approach is based on the observation that all quaternions of
norm-1 lie on the unit sphere in $\mathbb{R}^4$.  The authors use the
shortest connection between two points on a sphere, i.e. a great
circle.  For describing a movement on the sphere starting at
$\mathbf{h_0}$ they use a vector $v_4$ lying in the tangential
hyperplane that touches the sphere at $\mathbf{h_0}$. This hyper-plane
is a subspace of $\mathbb{R}^4$, thus vectors in this plane may be
represented as 3-vectors with respect to a plane-local coordinate
frame.

Experiments are made on a synthetic (small) data-set.  The authors
perform bundle adjustment and compare their approach with axis-angle
representation.  The conclusion is that this representation performs
better for rotations, for transnational motion both method are
approximately equal.

\bibliography{survey}{}
\bibliographystyle{plain}
\end{document}
