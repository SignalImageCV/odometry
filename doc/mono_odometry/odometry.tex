\documentclass[10pt]{article}         %% What type of document you're writing.

%%%%% Preamble

%% Packages to use

\usepackage{amsmath,amsfonts,amssymb,mathtools}   %% AMS mathematics macros
\usepackage{graphicx}
\usepackage[margin=1cm]{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{cite}
\usetikzlibrary{decorations.pathreplacing,matrix}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{decorations.text}

\tikzset{ 
  table/.style={
    matrix of math nodes,
    row sep=-\pgflinewidth,
    column sep=-\pgflinewidth,
    nodes={rectangle,text width=3em,align=center},
    text depth=1.0ex,
    text height=1.0ex,
    nodes in empty cells,
    left delimiter=[,
    right delimiter={]},
  }
}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\newtheorem{exmp}{Example}[section]
%% Title Information.

\title{Monocular methods in stereo visual odometry}
\author{Ilan Shimshoni, Ehud Rivlin, Alex Kreimer}

\begin{document}

\maketitle

\abstract{We propose a new algorithm for stereo visual odometry based on monocular methods}

\section{Introduction}
TBD

\section{Related Work}
TBD

\section{Algorithm Description}

The algorithm in ~\ref{algo} solves VO in stereo setting. It relies on
the estimation and decomposition of the essential matrix and the
invariance of the cross-ratio under projectile transformation so we
overview these first in ~\ref{sec:mono_odo} and ~\ref{sec:cross_ratio}

\subsection{Monocular motion estimation}\label{sec:mono_odo}
Let $C_1$ and $C_2$ be the two camera frames.  $R$ describes the
orientation of $C_1$ in as seen from $C_2$. $q_1$ is a direction (line
of site of the origin) from $C_2$ to $C_1$ described in $C_2$ (see
Figure ~\ref{fig:two_views})

Thus for every pair of image correspondences $x\in C_1,x'\in C_2$ holds
\[
x'^TK^{-1}[q]_{\times}RK^{-1}x=0
\]
where $K$ is an intrinsic parameters matrix and $E=[q]_{\times}R$ is
the essential matrix.  We estimate the fundamental
($F=K^{-1}[q]_{\times}RK^{-1}$) using a standard technique such as
normalized 8-point algorithm) and then strip it down to essential
matrix.  Further on we decompose the essential to obtain motion
parameters $q$ and $R$.  $R$ may be determined exactly while $q$ only
up to scale There are 4 different decompositions, which produce the
same essential, but only one is correct.  This ambiguity is resolved
by imposing the chierality constraint upon the scene points.

An in-depth review of fundamental matrix and its uncertainty
estimation is given in ~\cite{zhang1998determining}

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (4,3); \draw [dashed] (0,0)
    -- (2,2); \draw [->] (2,2) -- (1.5,1.5); \node [left] at (1.5,1.5)
    {$R,q_1$}; \draw [red, fill] (0,0) circle [radius=0.05]; \node
    [below left] at (0,0) {$C_1$}; \node [above left] at (2,2)
    {$C_2$}; \draw [red, fill] (2,2) circle [radius=0.05];
  \end{tikzpicture}
  \caption{Two views}
  \label{fig:two_views}
\end{figure}

\subsection{Cross-ratio}\label{sec:cross_ratio}

We propose to exploit the fact that most of the time the car goes more
or less straight forward.  This special case of camera motion
possesses peculiar cross-ratio related properties.

It is a known fact ~\cite{Hartley2004} that if camera motion is a pure
translation the projections of the world point will ``surf'' along the
epipolar line (towards the epipole or away from it depending on the
sign of the translation vector). It was also shown
~\cite{basri1999visual} that the cross ratio of feature locations and
the vanishing point is exactly the same as the one of the camera
centers and the ideal point and thus may be used as an additional
constraint in motion estimation.

We face two issues: decide when to use the cross ratio constraint and
how to incorporate it into the motion estimation process.

To address the first question we fit a line into the three last
feature locations and use the residuals to make a decision.  Thus,
given a triplet of (homogeneous) feature locations $p_i,p'_i,p''_i$ and the epipole
$e$ (see figure ~\ref{fig:cross_ratio}) we fit a line $w\in R^3$ by solving linear orthogonal regression (using QR decomposition and SVD):

\[
w_i^* = \underset{w}{\text{argmin}} \ \norm{A_iw_i}_2\ \text{s.t.}\
w^2_i[1]+w^2_i[2]=1
\]

where $A_i=[p_i,p'_i,p''_i,e]^T$.  The residuals are given by (the
summation is over all the features that are available in last three
images):
\begin{equation}\label{eq:puret}
  \hat{r}_t = \frac{1}{N} \sum_{i=1}^N A_iw_i^*
\end{equation}

Thus the value of $\hat{r}_t$ may be used to quantitatively assess how
``purely translational'' is the motion at time $t$.

The cross ratio for feature point $i$ is given by:
\[
Cr(p_i,p'_i,p''_i,e) =
\frac{\norm{p''_i-p_i}\norm{e-p'_i}}{\norm{p'_i-p_i}\norm{e-p''_i}}
\]
Let $O,O',O''$ be the centers of the cameras for $p_i,p'_i,p''_i$
respectively and let $V_\infty$ be the ideal point of camera motion.
Thus for every feature point $i$ holds:
\[
Cr(O,O',O'',V_{\infty}) = Cr(p_i,p'_i,p''_i,e) \;
\]

Let us denote $Cr_t = Cr(O,O',O'',V_{\infty})$.

Since the locations of the features are noisy we compute average
cross-ratio value:
\[
\hat{Cr} =  \frac{1}{N}\sum_{i=1}^NCr(p_i,p'_i,p''_i,e) \;
\]

And thus for time $t$ we have:
\begin{equation}\label{eq:cr}
  Cr_t = \hat{Cr}
\end{equation}

We will use both ~\ref{eq:puret} and ~\ref{eq:cr} in the motion
parameter fitting procedure.

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (6,3); \draw [->] (0,0) --
    (5,3); \draw [green, fill] (0,0) circle [radius=0.02]; \draw
    [green, fill] (1,.6) circle [radius=0.02]; \draw [green, fill]
    (3.35,2) circle [radius=0.02]; \draw [green, fill] (5,3) circle
    [radius=0.02]; \node [above left] at (0,0) {$p_i$}; \node [above
    left] at (1,.6) {$p'_i$}; \node [above left] at (3.35,2) {$p''_i$};
    \node [above left] at (5,3) {$e$};
  \end{tikzpicture}
  \caption{Feature motion feature along the epipolar line during
    camera translation.  The cross ratio $Cr(p_i,p'_i,p''_i,e) =
    \frac{\norm{p''_i-p_i}\norm{e-p'_i}}
    {\norm{p'_i-p_i}\norm{e-p''_i}}$ has the same value for all
    features in the image.}
  \label{fig:cross_ratio}
\end{figure}

\subsection{Stereo setup}

\subsubsection{Stereo motion estimation}\label{algo}

\paragraph{Problem statement} Let $C_t/C_t' \in \mathbf{SE}(3) $
denote the pose of the left/right camera (respectively) at time $t$ as
seen in the world coordinate frame (usually placed at $C_1$). The rig is
moving rigidly, i.e., there is $T_t \in \mathbf{SE}(3)$ s.t. $ C_t =
T_t*C_{t-1}; C'_t = T_t*C'_{t-1}$ (see Figure ~\ref{fig:stereo_rig}).
Our goal is to estimate $T_t$ given the images taken by the camera at
times $\{t,t-1 \ldots t-k\}$

The algorithm presented in ~\ref{sec:mono_odo} may determine
rotation completely and translation up to scale.  In case of a stereo
rig we can also determine the scale of the translation.  Below is the
algorithm outline:

\paragraph{Algorithm 1 (initial estimate)}
\begin{enumerate}
\item Estimate $T_t=[R_t,q_t]$ using the algorithm in ~\ref{sec:mono_odo}
\item Estimate $T'_t=[R'_t,q'_t]$ the same way
\item Let $c_1,c_2$ be the real scales of $q_1,q_2$. We solve for
  scale by enforcing $c_1q_1+c_2q_2 = t_0$ (we assume that all vectors
  are given in the same frame, e.g., the $C_1$).  The same equations
  may be written in matrix form $Qc=t_0$.  Where $Q = [q_1, q_2] \in
  R^{3\times2}$ and $c=[c_1,c_2]^T$.  Since the system has 3
  constraints and 2 variables we solve LS problem instead (using SVD)
  $c^* = \underset{c}{argmin}\ \norm{Qc-t_0}$
\end{enumerate}

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (6,3); \draw [dashed] (0,0)
    -- (2,2); \draw [dashed] (3,0) -- (2,2); \draw [->] (0,0) --
    (.5,.5); \node [left] at (.5,.5) {$T_t=[R_t,q_t]$}; \draw [->] (3,0) --
    (2.75,.5); \node [right] at (2.75,.5) {$T'_t=[R'_t,q'_t]$}; \draw [red, fill]
    (0,0) circle [radius=0.05]; \draw [blue, fill] (3,0) circle
    [radius=0.05]; \node [below left] at (0,0) {$C_{t-1}$}; \node [below
    right] at (3,0) {$C_{t-1}'$}; \node [above left] at (2,2) {$C_t$};
    \node [above right] at (5,2) {$C_t'$}; \draw [red, fill] (2,2)
    circle [radius=0.05]; \draw [blue, fill] (5,2)
    circle [radius=0.05];
  \end{tikzpicture}
  \caption{Motion of a stereo rig}
  \label{fig:stereo_rig}
\end{figure}


\subsection{Essential Matrix refinement step}

We follow approach proposed in ~\cite{Botterill-etal-2011c} to refine
camera motion parameters. Let $r_i(E)$ be the Sampson's error
approximation:

\[
r_i(E) = \frac{x_i'^TEx_i}{\sqrt{(x_i'^TE)^2_0+(x_i'^TE)^2_1+(Ex_i)^2_0+(Ex_i)^2_1}}
\]

If point localization errors are approximately Gaussian, given N
correctly matched features $\{(x_i,x_i') | i=1\ldots N\}$ the MLE of E is approximately
the point where $\sum_{i=1}^{N} r_i(E)^2$ is minimized.

It is common to minimize functions in the form of sum of squares using
the Levenberg-Marquardt (LM) algorithm ~\cite{marquardt1963algorithm},
a dynamically damped version of Gauss-Newton.  It is also common to
use robust cost functions to cope with outliers (which break Gaussian
residual assumption).  This is known as Iteratively Reweighted Least
Squares, or IRLS ~\cite{Hartley2004}.  To minimize a function
$\sum_{i=1}^N C(r_i)$ for an arbitrary cost function C using IRLS,
weights $\{w_i\}$ are chosen so that $(w_ir_i)^2=C(r_i)$. The function
$\sum_{i=1}^N (w_ir_i)^2$ is minimized by LM, with weights recomputed
at each iteration.

$E$ is parameterized as a function $E(q,t)$ of a unit translation
vector $t$, and a rotation, which is expressed as a quaternion
$q$. Unit quaternions represent 3D rotations as 4D vectors. 4D unit
vectors form the differential manifold $\mathbb{S}^3$ (a unit sphere
in $R^4$).

At each iteration, the manifold $\mathbb{S}^3$ is parameterized as
three orthogonal vectors $\tau_1,\tau_2,\tau_3$ tangent to the sphere
$\mathbb{S}^3$ at $q$.  For each correspondence $(x_i,x_i')$, the
derivative of the cost function in the direction $\tau_j$ is computed
by finite differences.

 We define the following objective:
\begin{align*}
  F &= \sum_{i=1}^{N_1}{ r_i(E_1)^2 } + \sum_{j=1}^{N_2}{ r_j(E_2)^2 }
  + \norm{Qc-t_0}^2 + \frac{\lambda}{w(\hat{r_t})}(Cr_t - \hat{Cr})^2
\end{align*}

\subsection{Implementation Details}
TBD

\section{Results}
TBD

\bibliographystyle{plain}
\bibliography{sample}

\end{document}
