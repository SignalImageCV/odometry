\documentclass[10pt]{article}         %% What type of document you're writing.

%%%%% Preamble

%% Packages to use

\usepackage{amsmath,amsfonts,amssymb,mathtools}   %% AMS mathematics macros
\usepackage{graphicx}
\usepackage[margin=1cm]{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{cite}
\usetikzlibrary{decorations.pathreplacing,matrix}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{decorations.text}

\tikzset{ 
  table/.style={
    matrix of math nodes,
    row sep=-\pgflinewidth,
    column sep=-\pgflinewidth,
    nodes={rectangle,text width=3em,align=center},
    text depth=1.0ex,
    text height=1.0ex,
    nodes in empty cells,
    left delimiter=[,
    right delimiter={]},
  }
}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\newtheorem{exmp}{Example}[section]
%% Title Information.

\title{Monocular methods in stereo visual odometry}
\author{Ilan Shimshoni, Ehud Rivlin, Alex Kreimer}

\begin{document}

\maketitle

\abstract{We propose a new algorithm for stereo visual odometry based on monocular methods}

\section{Introduction}
TBD

\section{Related Work}
TBD

\section{Algorithm Description}

The proposed algorithm solves VO in stereo setting. It relies on the
monocular methods and the concept of cross-ratio so we overview them
first in ~\ref{sec:mono_odo} and ~\ref{sec:cross_ratio}

\subsection{Monocular motion estimation}\label{sec:mono_odo}
$R$ describes the orientation of $C_1$ in as seen from $C_2$. $q_1$ is
a direction (line of site of the origin) from $C_2$ to $C_1$ described
in $C_2$ (see Figure ~\ref{fig:two_views})

Thus for every pair of image correspondences $x\in C_1,x'\in C_2$ holds
\[
x'^TK^{-1}[q]_{\times}RK^{-1}x=0
\]
where $K$ is an intrinsic parameters matrix and $E=[q]_{\times}R$ is
the essential matrix.  We estimate the fundamental
($F=K^{-1}[q]_{\times}RK^{-1}$) using a standard technique such as
normalized 8-point algorithm) and then strip it down to essential
matrix.  Further on we decompose the essential to obtain motion
parameters $q$ and $R$.  $R$ may be determined exactly while $q$ only
up to scale There are 4 different decompositions, which produce the
same essential, but only one is correct.  This ambiguity is resolved
by imposing the chierality constraint upon the scene points.

An in-depth review of fundamental matrix and its uncertainty
estimation is given in ~\cite{zhang1998determining}

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (4,3); \draw [dashed] (0,0)
    -- (2,2); \draw [->] (2,2) -- (1.5,1.5); \node [left] at (1.5,1.5)
    {$R,q_1$}; \draw [red, fill] (0,0) circle [radius=0.05]; \node
    [below left] at (0,0) {$C_1$}; \node [above left] at (2,2)
    {$C_2$}; \draw [red, fill] (2,2) circle [radius=0.05];
  \end{tikzpicture}
  \caption{Two views}
  \label{fig:two_views}
\end{figure}

\subsection{Cross-ratio}\label{sec:cross_ratio}

We propose to exploit the fact that most of the time the car goes more
or less straight forward.  This special case of camera motion
possesses peculiar cross-ratio related properties, which may be
exploited.

It is a known fact ~\cite{Hartley2004} that if camera motion is a pure
translation the projections of the world point will ``surf'' along the
epipolar line (towards the epipole or away from it depending on the
sign of the translation vector). It was also shown
~\cite{basri1999visual} that the cross ratio of feature locations and
the vanishing point is exactly the same as the one of the camera
centers and the ideal point and thus may be used as an additional
constraint in motion estimation.

We face two issues: decide when to use the cross ratio constraint and
how to incorporate it into the motion estimation process.

To address the first question we fit a line into the three last
feature locations and use the residuals to make a decision.  Thus
given a triplet of feature locations $p_i,p'_i,p''_i$ and the epipole
$e$ we fit a line $w$ by solving linear orthogonal regression

\[
w_i^* = \underset{w}{\text{argmin}} \ \norm{A_iw_i}_2\ \text{s.t.}\
\norm{w_i}_2=1
\]

where $A_i=[p_i,p'_i,p''_i,e]^T$.  The residuals are given by (the
summation is over all the features that are available in last three
images):
\begin{equation}\label{eq:puret}
  \hat{r}_t = \frac{1}{N} \sum_{i=1}^N \frac{A_iw_i^*}{\sqrt{(w_i[1])^2+(w_i[2])^2}}
\end{equation}

Thus the value of $\hat{r}_t$ may be used to quantitatively assess how
linear is the motion at time $t$.

The cross ratio for feature point $i$ is given by:
\[
Cr(p_i,p'_i,p''_i,e) =
\frac{\norm{p''_i-p_i}\norm{e-p'_i}}{\norm{p''_i-p'_i}\norm{e-p_i}}
\]
Let $O,O',O''$ be the centers of the cameras for $p_i,p'_i,p''_i$
respectively and let $V_\infty$ be the ideal point of camera motion.
Thus for every feature point $i$ holds:
\[
Cr(O,O',O'',V_{\infty}) = Cr(p_i,p'_i,p''_i,e) \;
\]

Let us denote $Cr_t = Cr(O,O',O'',V_{\infty})$.

Since the locations of the features are noisy we compute average
cross-ratio value:
\[
\hat{Cr} =  \frac{1}{N}\sum_{i=1}^NCr(p_i,p'_i,p''_i,e) \;
\]

And thus for time $t$ we have:
\begin{equation}\label{eq:cr}
  Cr_t = \hat{Cr}
\end{equation}

We will use both ~\ref{eq:puret} and ~\ref{eq:cr} in the motion
parameter fitting procedure.

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (6,3); \draw [->] (0,0) --
    (5,3); \draw [green, fill] (0,0) circle [radius=0.02]; \draw
    [green, fill] (1,.6) circle [radius=0.02]; \draw [green, fill]
    (3.35,2) circle [radius=0.02]; \draw [green, fill] (5,3) circle
    [radius=0.02]; \node [above left] at (0,0) {$p_i$}; \node [above
    left] at (1,.6) {$p'_i$}; \node [above left] at (3.35,2) {$p''_i$};
    \node [above left] at (5,3) {$e$};
  \end{tikzpicture}
  \caption{Feature motion feature along the epipolar line during
    camera translation.  The cross ratio $Cr(p_i,p'_i,p''_i,e) =
    \frac{\norm{p''_i-p_i}\norm{e-p'_i}}{\norm{p''_i-p'_i}\norm{e-p_i}}$
    has the same value for all features in the image.}
  \label{fig:cross_ratio}
\end{figure}

\subsection{Stereo setup}

\subsubsection{Stereo motion estimation}
Let $C_t$ and $C_t'$ be the poses of the left/right camera at time
$t$. The rig is moving rigidly and we are interested to recover its
motion. See Figure ~\ref{fig:stereo_rig}

The algorithm presented in ~\ref{sec:mono_odo} may determine
rotation completely and translation up to scale.  In case of a stereo
rig we can also determine the scale of the translation.  Below is the
algorithm outline:

\paragraph{Algorithm outline} This procedure is used to initialize the
values of the parameters for non-linear refinement
\begin{enumerate}
\item Estimate $R_1,q_1$ using the algorithm in ~\ref{sec:mono_odo}
\item Estimate $R_2,q_2$ the same way
\item Let $c_1,c_2$ be the real scales of $q_1,q_2$. We solve for
  scale by enforcing $c_1q_1+c_2q_2 = t_0$ (we assume that all vectors
  are given in the same frame, e.g., the $C_1$).  The same equations
  may be written in matrix form $Qc=t_0$.  Where $Q = [q_1, q_2] \in
  R^{3\times2}$ and $c=[c_1,c_2]^T$.  Since the system has 3
  constraints and 2 variables we solve LS problem instead (using SVD)
  $c^* = \underset{c}{argmin}\ \norm{Qc-t_0}$
\end{enumerate}

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \draw [help lines, dotted] (0,0) grid (6,3); \draw [dashed] (0,0)
    -- (2,2); \draw [dashed] (3,0) -- (2,2); \draw [->] (0,0) --
    (.5,.5); \node [left] at (.5,.5) {$R_1,q_1$}; \draw [->] (3,0) --
    (2.75,.5); \node [right] at (2.75,.5) {$R_2,q_2$}; \draw [red, fill]
    (0,0) circle [radius=0.05]; \draw [blue, fill] (3,0) circle
    [radius=0.05]; \node [below left] at (0,0) {$C_1$}; \node [below
    right] at (3,0) {$C_1'$}; \node [above left] at (2,2) {$C_2$};
    \node [above right] at (5,2) {$C_2'$}; \draw [red, fill] (2,2)
    circle [radius=0.05]; \draw [blue, fill] (5,2)
    circle [radius=0.05];
  \end{tikzpicture}
  \caption{Motion of a stereo rig}
  \label{fig:stereo_rig}
\end{figure}


\subsection{Refinement step}

At this step we have a (hopefully) good initial guess for the motion
of the rig and we would like to refine it. Such two-step approach is
common for the camera motion estimation algorithms.  There are
numerous ways to address this question, reviewed in
~\cite{Botterill-etal-2011c}.  As the authors suggest we use Sampson's
error, that is given by:
\[
r_i(E) = \frac{x_i'^TEx_i}{\sqrt{(x_i'^TE)^2_0+(x_i'^TE)^2_1+(Ex_i)^2_0+(Ex_i)^2_1}}
\]

We define the following objective:
\begin{align*}
  F &= \sum_{i=1}^{N_1}{ r_i(E_1)^2 } + \sum_{j=1}^{N_2}{ r_j(E_2)^2 }
  + \norm{Qc-t_0}^2 + \frac{\lambda}{w(\hat{r_t})}(Cr_t - \hat{Cr})^2
\end{align*}

\subsubsection{Minimization details}

Gauss-Newton method for this problem is:
\begin{align*}
  r_i &= x_i'^TK^{-1}[q]_{\times}RK^{-1}x_i\\
  r_{N+1} &= \lambda(q^Tq-1)
\end{align*}

So,
\begin{align*}
  F(q,R) &= r^Tr = \sum_i^{N+1} r_i^2\\
  (\nabla F)_j& = \sum_i^{N+1} 2 r_i (\nabla r_i)_j\ \text{and thus, } \nabla F = 2J^Tr\quad\text{where, } J=[\nabla r_1 \nabla r_2 \ldots \nabla r_{N+1}]^T\\
  (\nabla^2 F)_{jk} &= 2\sum_i^{N+1} (\nabla r_i)_k (\nabla r_i)_j+r_i(\nabla^2 r_i)_{jk}\ \approx 2\sum_i^{N+1} (\nabla r_i)_k (\nabla r_i)_j\\
  \nabla^2 F &\approx 2J^TJ
\end{align*}

\section{Appendix: commonly used derivatives}
\[
f_i(r_x,r_y,r_z,t_x,t_y,t_z) = x_i^T[t]_xRx'_i
\]
where
\[
R(r_x,r_y,r_z)=R_x(r_x)R_y(r_y)R_z(r_z)=
\begin{bmatrix}
  c_yc_z & -c_ys_z &s_y\\
  s_xs_yc_z+c_xs_z &-s_xs_ys_z+c_xc_z &-s_xc_y\\
  -c_xs_yc_z+s_xs_z &c_xs_ys_z+s_xc_z &c_xc_y
\end{bmatrix}
\] 
and $[t]_x=\begin{bmatrix}0 &-t_z &t_y\\t_z &0 &-t_x\\-t_y &t_x
  &0\end{bmatrix}$

\begin{align*}
  \frac{\partial f}{\partial r_x} 
  &= x_i^T[t]_x\frac{\partial R}{\partial r_x}x'_i
  &= x_i^T\begin{bmatrix} 0 &-t_z &t_y\\t_z &0 &-t_x\\-t_y &t_x &0 \end{bmatrix}
  \begin{bmatrix} 0 & 0 &0\\c_xs_yc_z-s_xs_z &-c_xs_ys_z-s_xc_z &-c_xc_y\\
    s_xs_yc_z+c_xs_z &-s_xs_ys_z+c_xc_z &-s_xc_y \end{bmatrix}x'_i
\end{align*}

\begin{align*}
  \frac{\partial f}{\partial r_y} 
  &= x_i^T[t]_x\frac{\partial R}{\partial r_y}x'_i
  &= x_i^T\begin{bmatrix} 0 &-t_z &t_y\\t_z &0 &-t_x\\-t_y &t_x &0\\ \end{bmatrix}
  \begin{bmatrix} -s_yc_z & s_yc_z &c_y\\c_xc_yc_z &-c_xc_ys_z &c_xs_y\\
    -s_xc_yc_z &s_xc_ys_z &-s_xs_y \end{bmatrix}x'_i
\end{align*}

\begin{align*}
  \frac{\partial f}{\partial r_z} 
  &= x_i^T[t]_x\frac{\partial R}{\partial r_z}x'_i
  &= x_i^T\begin{bmatrix} 0 &-t_z &t_y\\t_z &0 &-t_x\\-t_y &t_x &0\\ \end{bmatrix}
  \begin{bmatrix} -c_ys_z& c_ys_z &0\\-s_xs_ys_z+c_xc_z &-s_xs_yc_z-c_xs_z &0\\
    c_xs_ys_z+c_xs_z &c_xs_yc_z-c_xs_z &0 \end{bmatrix}x'_i
\end{align*}

\bibliographystyle{plain}
\bibliography{sample}

\end{document}
